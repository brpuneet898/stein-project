{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "UhfRLSMxRiJb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SVGD:\n",
        "    def __init__(self, bandwidth=None, step_size=1e-2):\n",
        "        self.bandwidth = bandwidth\n",
        "        self.step_size = step_size\n",
        "\n",
        "    def _rbf_kernel(self, X):\n",
        "        n, d = X.shape\n",
        "        pairwise_dists = np.sum((X[:, None, :] - X[None, :, :]) ** 2, axis=2)\n",
        "        h = self.bandwidth\n",
        "        if h is None:\n",
        "            h = np.median(pairwise_dists)\n",
        "            h = 0.5 * h / np.log(n + 1)\n",
        "\n",
        "        K = np.exp(-pairwise_dists / h)\n",
        "        grad_K = -np.matmul(K, X) + X * np.sum(K, axis=1, keepdims=True)\n",
        "        grad_K *= (2 / h)\n",
        "        return K, grad_K\n",
        "\n",
        "    def update(self, particles, grad_log_p):\n",
        "        score = grad_log_p(particles)\n",
        "        K, grad_K = self._rbf_kernel(particles)\n",
        "        phi = (np.matmul(K, score) + grad_K) / particles.shape[0]\n",
        "        return particles + self.step_size * phi"
      ],
      "metadata": {
        "id": "UGLK_kBER6Qa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_posterior(x):\n",
        "    \"\"\"Log probability of a standard 2D Gaussian.\"\"\"\n",
        "    return -0.5 * np.sum(x**2, axis=1)\n",
        "\n",
        "def grad_log_posterior(x):\n",
        "    \"\"\"Gradient of the log probability (standard Gaussian).\"\"\"\n",
        "    return -x"
      ],
      "metadata": {
        "id": "tcsOaHfhR8fx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_gradient_validity():\n",
        "    particles = np.random.randn(100, 2)\n",
        "    grad = grad_log_posterior(particles)\n",
        "    assert grad.shape == particles.shape, \"Gradient shape mismatch.\"\n",
        "    assert not np.isnan(grad).any(), \"Gradient contains NaNs.\"\n",
        "    print(\"✅ Gradient shape and NaN check passed.\")"
      ],
      "metadata": {
        "id": "2uZ1YLYaR-T0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_kl(p_samples, log_q_fn):\n",
        "    log_q = log_q_fn(p_samples)\n",
        "    log_p = -0.5 * np.sum(p_samples ** 2, axis=1)\n",
        "    return np.mean(log_p - log_q)"
      ],
      "metadata": {
        "id": "iPWmfcqRSAC-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_kl_divergence_decreases():\n",
        "    np.random.seed(42)\n",
        "    svgd = SVGD()\n",
        "    n_particles = 100\n",
        "    dim = 2\n",
        "    iterations = 300\n",
        "\n",
        "    particles = np.random.randn(n_particles, dim)\n",
        "    kl_values = []\n",
        "\n",
        "    for i in range(iterations):\n",
        "        particles = svgd.update(particles, grad_log_posterior)\n",
        "        if i % 50 == 0:\n",
        "            kl = compute_kl(particles, log_posterior)\n",
        "            kl_values.append(kl)\n",
        "\n",
        "    assert all(earlier >= later for earlier, later in zip(kl_values, kl_values[1:])), \\\n",
        "        f\"KL did not decrease over time: {kl_values}\"\n",
        "    print(\"✅ KL divergence decreases test passed.\")"
      ],
      "metadata": {
        "id": "ngxA9ZGTSBgC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_wall_time_under_limit():\n",
        "    np.random.seed(0)\n",
        "    svgd = SVGD()\n",
        "    n_particles = 100\n",
        "    dim = 2\n",
        "    iterations = 1000\n",
        "    time_budget_seconds = 20\n",
        "\n",
        "    particles = np.random.randn(n_particles, dim)\n",
        "    start_time = time.time()\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        particles = svgd.update(particles, grad_log_posterior)\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    assert elapsed <= time_budget_seconds, f\"Wall-time exceeded: {elapsed:.2f}s > {time_budget_seconds}s\"\n",
        "    print(f\"✅ Wall-time test passed: {elapsed:.2f} seconds for {iterations} iterations\")"
      ],
      "metadata": {
        "id": "VeooU_-2SDft"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    test_gradient_validity()\n",
        "    test_kl_divergence_decreases()\n",
        "    test_wall_time_under_limit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKn21dF3SFVW",
        "outputId": "5d22f49e-1fa8-40ba-bbf1-2fdb755ae0e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gradient shape and NaN check passed.\n",
            "✅ KL divergence decreases test passed.\n",
            "✅ Wall-time test passed: 0.87 seconds for 1000 iterations\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}